services:
  tei-embedder:
    image: ghcr.io/huggingface/text-embeddings-inference:${HF_TEI_TAG}
    container_name: tei-embed
    networks:
      - genai
      - proxy
    volumes:
      - ${DATA_DIR}:/data
    environment:
      - MAX_CLIENT_BATCH_SIZE=${EMBEDDER_BATCH_SIZE}
    command:
      - --hostname=0.0.0.0
      - --port=4000
      - --hf-token=${HF_TOKEN}
      - --model-id=${EMBEDDER_MODEL}
      - --dtype=${EMBEDDER_DTYPE}
      - --max-batch-tokens=${EMBEDDER_BATCH_TOKENS}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['${GPU_ID}']
              capabilities: [gpu]

  tei-reranker:
    image: ghcr.io/huggingface/text-embeddings-inference:${HF_TEI_TAG}
    container_name: tei-rerank
    networks:
      - genai
      - proxy
    volumes:
      - ${DATA_DIR}:/data
    environment:
      - MAX_CLIENT_BATCH_SIZE=${RERANKER_BATCH_SIZE}
    command:
      - --hostname=0.0.0.0
      - --port=4000
      - --hf-token=${HF_TOKEN}
      - --model-id=${RERANKER_MODEL}
      - --dtype=${RERANKER_DTYPE}
      - --max-batch-tokens=${RERANKER_BATCH_TOKENS}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['${GPU_ID}']
              capabilities: [gpu]

  tei-proxy:
    image: ${PROXY_IMAGE}
    container_name: tei-proxy
    networks:
      - genai
      - proxy
    environment:
      - MAX_CLIENT_BATCH_SIZE=${RERANKER_BATCH_SIZE}
      - TEI_ENDPOINT=http://tei-rerank:4000
      - TEI_PROXY_PORT=${PROXY_PORT}
      - RUST_LOG=${PROXY_LOG_LEVEL}

networks:
  genai:
    external: true
  proxy:
    external: true
