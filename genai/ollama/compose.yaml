services:
  ollama:
    image: ollama/ollama:${OLLAMA_TAG}
    container_name: ollama
    restart: "no"
    networks:
      - genai
      - proxy
    ports:
      - 127.0.0.1:11434:11434
    env_file:
      - ./ollama.env
    volumes:
      - ${DATA_DIR}:/root/.ollama
    devices:
      - nvidia.com/gpu=0
      - nvidia.com/gpu=1

  ollama-summarizer:
    image: ollama/ollama:${OLLAMA_TAG}
    container_name: ollama-summarizer
    restart: "no"
    networks:
      - genai
      - proxy
    ports:
      - 127.0.0.1:11435:11434
    env_file:
      - ./ollama.env
    environment:
      - OLLAMA_KEEP_ALIVE=-1
    volumes:
      - ${DATA_DIR}:/root/.ollama
    devices:
      - nvidia.com/gpu=1

  ollama-summarizer-loader:
    image: alpine/curl
    container_name: ollama-summarizer-loader
    restart: "no"
    networks:
      - genai
    depends_on:
      - ollama-summarizer
    volumes:
      - ./preload.sh:/preload.sh:ro
    entrypoint: ["/bin/sh", "/preload.sh"]

networks:
  genai:
    external: true
  proxy:
    external: true
