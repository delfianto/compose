services:
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    container_name: litellm
    depends_on:
      - ollama
      - pgvector
    restart: always
    networks:
      - proxy
      - llm
    volumes:
      - ${DATA_DIR}/litellm.yaml:/app/config.yaml
    environment:
      - LITELLM_LOG=${LITELLM_LOG}
      - LITELLM_HOST=0.0.0.0
      - LITELLM_SALT_KEY=${LITELLM_SALT_KEY}
      - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY}
      # API keys to various external services
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      # Vector database for semantic caching
      - QDRANT_API_BASE=${QDRANT_API_BASE}
      # General database configurations
      - DATABASE_URL=postgresql://litellm:${POSTGRES_PASSWORD}@pgvector:5432/litellm
    command:
      - "--config"
      - "/app/config.yaml"
      - "--port"
      - "4000"
    labels:
      # Traefik integration
      - "traefik.enable=true"
      - "traefik.http.routers.litellm.entrypoints=websecure"
      - "traefik.http.routers.litellm.rule=Host(`litellm.${TRAEFIK_ACME_DOMAIN}`)"
      - "traefik.http.routers.litellm.tls.certresolver=cloudflare"
      - "traefik.http.services.litellm.loadbalancer.server.port=4000"
      # Homepage integration
      - "homepage.group=Artificial Intelligence"
      - "homepage.name=LiteLLM"
      - "homepage.icon=anything-llm.svg"
      - "homepage.href=https://litellm.${TRAEFIK_ACME_DOMAIN}/ui"
